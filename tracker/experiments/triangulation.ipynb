{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.71007943]\n",
      " [ 0.21607947]\n",
      " [-0.02937308]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "P1 = np.array([[-6.5920441e+01,  8.5485431e+02, -4.0555966e+02,  1.2354684e+03],\n",
    "       [ 5.9958112e+02,  4.3894717e+02,  2.5966882e+02,  1.1042605e+03],\n",
    "       [ 5.5738282e-01,  4.6548709e-01, -6.8749267e-01,  1.9879433e+00]], dtype=np.float32)\n",
    "\n",
    "P2 = np.array([[-8.0220477e+02, -4.8673218e+01, -5.0368481e+02,  1.2422305e+03],\n",
    "       [-4.5547061e+02,  6.0689667e+02,  2.0933946e+02,  1.1396505e+03],\n",
    "       [-3.7105042e-01,  5.6809044e-01, -7.3457122e-01,  1.9341261e+00]], dtype=np.float32)\n",
    "\n",
    "hP = cv2.triangulatePoints(P1, P2, np.array([867, 454], dtype=np.float32), np.array([778, 673], dtype=np.float32))\n",
    "hP /= hP[3]\n",
    "\n",
    "print(hP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 1280\n",
    "HEIGHT = 720\n",
    "\n",
    "focal_length = 2.1\n",
    "#focal_length = 3.6651 # calculated from sensor width and fov\n",
    "principal_point = (WIDTH//2, HEIGHT//2)\n",
    "\n",
    "camera_matrix = np.array([\n",
    "    [focal_length/0.003, 0, 640],\n",
    "        [0, focal_length/0.003, 360],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "dist_coeffs = np.array([1.40017137e-14, 2.14617695e-10, -1.38004061e-16, 2.35596742e-16, -6.64757209e-15], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera0_points = np.array([(673, 489), (748, 595), (547, 616)], dtype=np.float32)\n",
    "camera2_points = np.array([(468, 537), (542, 792), (742, 819)], dtype=np.float32)\n",
    "camera4_points = np.array([(513, 531), (745, 593), (564, 636)], dtype=np.float32)\n",
    "\n",
    "R0 = np.array([\n",
    "    [-0.58837329, 0.80851857, 0.01070471],\n",
    "    [ 0.57393726, 0.40826571, 0.7098698 ],\n",
    "    [ 0.56957255, 0.42381226, -0.70425158]],\n",
    "    dtype=np.float32)\n",
    "\n",
    "R2 = np.array([\n",
    "    [ 0.9992472,   0.03586689, -0.01478517],\n",
    "    [ 0.03719431, -0.99405785,  0.10230139],\n",
    "    [-0.01102809, -0.10277431, -0.99464357]], \n",
    "    dtype=np.float32)\n",
    "\n",
    "R4 = np.array([\n",
    "    [-0.7412358,  -0.66257897,  0.10751094],\n",
    "    [-0.43003066,  0.59172124,  0.6818648 ],\n",
    "    [-0.51540579,  0.45918959, -0.72353424]], \n",
    "    dtype=np.float32)\n",
    "\n",
    "t0 = np.array([[-0.06891478], [ 0.57787268], [2.0068106]], dtype=np.float32)\n",
    "t2 = np.array([[-0.74057171], [0.32127425], [0.05085222]], dtype=np.float32)\n",
    "t4 = np.array([[0.05593381], [0.65855964], [2.13014952]], dtype=np.float32)\n",
    "\n",
    "Rt0 = np.hstack((R0, t0))\n",
    "Rt2 = np.hstack((R2, t2))\n",
    "Rt4 = np.hstack((R4, t4))\n",
    "\n",
    "P0 = camera_matrix @ Rt0\n",
    "P2 = camera_matrix @ Rt2\n",
    "P4 = camera_matrix @ Rt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fundamental_matrix(K1, K2, R1, R2, t1, t2):\n",
    "    R = R2 @ R1.T #relative rotation\n",
    "    t = t2 - R @ t1 #relative translation\n",
    "\n",
    "\n",
    "    # Compute skew-symmetric matrix of t\n",
    "    t_skew = np.array([\n",
    "        [0, -t[2, 0], t[1, 0]],\n",
    "        [t[2, 0], 0, -t[0, 0]],\n",
    "        [-t[1, 0], t[0, 0], 0]\n",
    "    ])\n",
    "\n",
    "    # Compute Essential Matrix\n",
    "    E = t_skew @ R\n",
    "\n",
    "    # Compute Fundamental Matrix\n",
    "    F = np.linalg.inv(K2).T @ E @ np.linalg.inv(K1)\n",
    "\n",
    "    # Normalize Fundamental Matrix\n",
    "    F /= np.linalg.norm(F)\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_epipolar_constraint(F, p1, p2):\n",
    "\n",
    "    p1 = np.array([p1[0], p1[1], 1])\n",
    "    p2 = np.array([p2[0], p2[1], 1])\n",
    "\n",
    "    print(p1, p2)\n",
    "    print(p2 @ F @ p1)\n",
    "\n",
    "    return np.abs(p2 @ F @ p1) < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[673. 489.   1.] [513. 531.   1.]\n",
      "-0.04200248374479543\n",
      "[673. 489.   1.] [745. 593.   1.]\n",
      "-0.004117949355885275\n",
      "[673. 489.   1.] [564. 636.   1.]\n",
      "-0.10266013602947921\n",
      "[748. 595.   1.] [513. 531.   1.]\n",
      "0.07028054443192044\n",
      "[748. 595.   1.] [745. 593.   1.]\n",
      "0.08191906693993978\n",
      "[748. 595.   1.] [564. 636.   1.]\n",
      "-0.00037972436436761736\n",
      "[547. 616.   1.] [513. 531.   1.]\n",
      "-0.003969989559112652\n",
      "[547. 616.   1.] [745. 593.   1.]\n",
      "0.020722782362544545\n",
      "[547. 616.   1.] [564. 636.   1.]\n",
      "-0.05814531665048528\n"
     ]
    }
   ],
   "source": [
    "foundCorrespondences = []\n",
    "\n",
    "for point0 in camera0_points:\n",
    "    for point4 in camera4_points:\n",
    "        if(check_epipolar_constraint(get_fundamental_matrix(camera_matrix, camera_matrix, R0, R4, t0, t4), point0, point4)):\n",
    "            foundCorrespondences.append((point0, point4))\n",
    "#     for point4 in camera4_points:\n",
    "#         if(check_epipolar_constraint(get_fundamental_matrix(camera_matrix, camera_matrix, R0, R4, t0, t4), point0, point4)):\n",
    "#             foundCorrespondences.append((point0, point4))\n",
    "\n",
    "# for point2 in camera2_points:\n",
    "#     for point4 in camera4_points:\n",
    "#         if(check_epipolar_constraint(get_fundamental_matrix(camera_matrix, camera_matrix, R2, R4, t2, t4), point2, point4)):\n",
    "#             foundCorrespondences.append((point2, point4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[673. 489.] [745. 593.] [[-0.3473977 ]\n",
      " [-0.05675602]\n",
      " [-0.02339257]\n",
      " [ 1.        ]]\n",
      "[748. 595.] [564. 636.] [[-0.02144227]\n",
      " [ 0.49490538]\n",
      " [-0.02843176]\n",
      " [ 1.        ]]\n",
      "[547. 616.] [513. 531.] [[ 0.4852258 ]\n",
      " [ 0.06063693]\n",
      " [-0.03111175]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "triangulated_points = []\n",
    "\n",
    "for point0, point1 in foundCorrespondences:\n",
    "    homogeneous_point = cv2.triangulatePoints(P0, P4, point0, point1)\n",
    "    point = homogeneous_point / homogeneous_point[3]\n",
    "    triangulated_points.append(point)\n",
    "    print(point0, point1, point)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/calib3d/src/triangulate.cpp:75: error: (-209:Sizes of input arguments do not match) Number of proj points coordinates must be == 2 in function 'icvTriangulatePoints'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m homogeneous_point \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriangulatePoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m675\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m577\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m617\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m647\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m point \u001b[38;5;241m=\u001b[39m homogeneous_point \u001b[38;5;241m/\u001b[39m homogeneous_point[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(point)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/calib3d/src/triangulate.cpp:75: error: (-209:Sizes of input arguments do not match) Number of proj points coordinates must be == 2 in function 'icvTriangulatePoints'\n"
     ]
    }
   ],
   "source": [
    "homogeneous_point = cv2.triangulatePoints(P0, P4, np.array([[675, 577]]).T, np.array([[617, 647]]).T)\n",
    "point = homogeneous_point / homogeneous_point[3]\n",
    "print(point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
